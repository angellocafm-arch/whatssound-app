/**
 * WhatsSound â€” AI Provider (Pluggable)
 * 
 * Abstraction layer for the dashboard AI assistant.
 * Swap between providers by changing the config.
 * 
 * Supported providers:
 * - 'mock'     â†’ Hardcoded responses (default, no API key needed)
 * - 'anthropic' â†’ Claude API (Anthropic)
 * - 'openai'   â†’ GPT-4 / GPT-4o (OpenAI)
 * - 'custom'   â†’ Any OpenAI-compatible endpoint (Ollama, Together, Groq, etc.)
 * 
 * Config is stored in localStorage for easy switching from dashboard.
 */

export interface AIConfig {
  provider: 'mock' | 'anthropic' | 'openai' | 'custom';
  apiKey?: string;
  model?: string;
  baseUrl?: string;       // For custom endpoints
  systemPrompt?: string;  // Override system prompt
}

export interface AIMessage {
  role: 'user' | 'assistant' | 'system';
  content: string;
}

const DEFAULT_SYSTEM_PROMPT = `Eres Leo, el asistente IA del dashboard de WhatsSound. 
Tu rol es analizar datos de la plataforma y ayudar a los administradores (Kike y Ãngel).

Contexto de la plataforma:
- WhatsSound es "el WhatsApp de la mÃºsica" â€” DJs crean sesiones, usuarios escuchan, votan canciones, chatean y envÃ­an propinas
- Base de datos PostgreSQL en Supabase con: perfiles, sesiones, canciones, votos, mensajes, propinas, follows
- La app estÃ¡ en fase de desarrollo/demo para inversores

Instrucciones:
- Responde en espaÃ±ol, conciso pero completo
- Usa emojis para hacer las respuestas visuales
- Si te dan datos de la DB, analÃ­zalos e identifica tendencias
- Puedes sugerir acciones pero nunca modificas datos
- Si no tienes datos suficientes, dilo honestamente`;

// â”€â”€â”€ Config management â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

const CONFIG_KEY = 'ws_ai_config';

export function getAIConfig(): AIConfig {
  try {
    const stored = localStorage.getItem(CONFIG_KEY);
    if (stored) return JSON.parse(stored);
  } catch {}
  return { provider: 'mock' };
}

export function setAIConfig(config: AIConfig) {
  try {
    localStorage.setItem(CONFIG_KEY, JSON.stringify(config));
  } catch {}
}

// â”€â”€â”€ Provider implementations â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async function callAnthropic(messages: AIMessage[], config: AIConfig): Promise<string> {
  const res = await fetch('https://api.anthropic.com/v1/messages', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'x-api-key': config.apiKey!,
      'anthropic-version': '2023-06-01',
      'anthropic-dangerous-direct-browser-access': 'true',
    },
    body: JSON.stringify({
      model: config.model || 'claude-sonnet-4-20250514',
      max_tokens: 1024,
      system: config.systemPrompt || DEFAULT_SYSTEM_PROMPT,
      messages: messages.filter(m => m.role !== 'system').map(m => ({
        role: m.role,
        content: m.content,
      })),
    }),
  });

  if (!res.ok) {
    const err = await res.text();
    throw new Error(`Anthropic error: ${res.status} â€” ${err}`);
  }

  const data = await res.json();
  return data.content?.[0]?.text || 'Sin respuesta';
}

async function callOpenAI(messages: AIMessage[], config: AIConfig): Promise<string> {
  const baseUrl = config.baseUrl || 'https://api.openai.com/v1';
  const res = await fetch(`${baseUrl}/chat/completions`, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'Authorization': `Bearer ${config.apiKey}`,
    },
    body: JSON.stringify({
      model: config.model || 'gpt-4o',
      messages: [
        { role: 'system', content: config.systemPrompt || DEFAULT_SYSTEM_PROMPT },
        ...messages.filter(m => m.role !== 'system'),
      ],
      max_tokens: 1024,
    }),
  });

  if (!res.ok) {
    const err = await res.text();
    throw new Error(`OpenAI error: ${res.status} â€” ${err}`);
  }

  const data = await res.json();
  return data.choices?.[0]?.message?.content || 'Sin respuesta';
}

// â”€â”€â”€ Mock responses â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

function getMockResponse(q: string): string {
  const ql = q.toLowerCase();
  if (ql.includes('usuario') || ql.includes('activo'))
    return 'ğŸ“Š **Usuarios:**\nâ€¢ Total registrados: 16\nâ€¢ Activos en sesiones: 16\nâ€¢ DJs registrados: 5\nâ€¢ Oyentes: 11\n\nLa plataforma estÃ¡ en fase de testing. Los datos mostrados son reales de Supabase.';
  if (ql.includes('sesiÃ³n') || ql.includes('sesion') || ql.includes('popular'))
    return 'ğŸµ **Sesiones activas: 4**\n\n1. Viernes Latino ğŸ”¥ â€” DJ Carlos Madrid (6 miembros)\n2. Chill & Study Beats â€” Luna DJ (4 miembros)\n3. Deep House Sunset â€” Sarah B (3 miembros)\n4. Techno Underground â€” Paco Techno (3 miembros)\n\nTodas las sesiones tiran de datos reales de Supabase.';
  if (ql.includes('revenue') || ql.includes('propina') || ql.includes('dinero'))
    return 'ğŸ’° **Propinas (seed data):**\nâ€¢ 6 propinas registradas\nâ€¢ Total: â‚¬26.00\nâ€¢ Media: â‚¬4.33\nâ€¢ Top tipper: Carlos Ruiz (â‚¬10)\n\nâš ï¸ Stripe no conectado aÃºn â€” las propinas son datos de prueba.';
  if (ql.includes('gÃ©nero') || ql.includes('genero'))
    return 'ğŸ¶ **GÃ©neros en sesiones activas:**\nâ€¢ ReggaetÃ³n / Latin â€” 1 sesiÃ³n\nâ€¢ Lo-fi / Chill â€” 1 sesiÃ³n\nâ€¢ Deep House / Tropical â€” 1 sesiÃ³n\nâ€¢ Techno / Industrial â€” 1 sesiÃ³n\n\nMix variado en las 4 sesiones activas.';
  if (ql.includes('resumen') || ql.includes('dÃ­a') || ql.includes('hoy'))
    return 'ğŸ“‹ **Resumen:**\n\nğŸ‘¥ 16 usuarios en la plataforma\nğŸ“¡ 4 sesiones activas, 1 finalizada\nğŸµ 10 canciones en cola\nğŸ’¬ 12 mensajes de chat\nğŸ’° 6 propinas (â‚¬26 total)\nğŸ‘¥ 16 miembros en sesiones\n\nâœ… Plataforma en testing. Datos reales de Supabase. Realtime activado en 5 tablas.';
  if (ql.includes('config') || ql.includes('modelo') || ql.includes('api') || ql.includes('cambiar'))
    return 'âš™ï¸ **ConfiguraciÃ³n IA:**\n\nProvider actual: **Mock** (respuestas locales)\n\nProviders disponibles:\nâ€¢ `anthropic` â€” Claude (Sonnet/Opus)\nâ€¢ `openai` â€” GPT-4o / GPT-4\nâ€¢ `custom` â€” Cualquier API OpenAI-compatible (Ollama, Groq, Together, etc.)\n\nPara cambiar: ve a Config en el sidebar del dashboard, secciÃ³n "Asistente IA". Solo necesitas API key + modelo.';
  return 'ğŸ¤” Puedo ayudarte con:\nâ€¢ Usuarios y actividad\nâ€¢ Sesiones en vivo\nâ€¢ Revenue y propinas\nâ€¢ GÃ©neros\nâ€¢ Resumen del dÃ­a\nâ€¢ Config del asistente IA\n\nÂ¿QuÃ© necesitas?';
}

// â”€â”€â”€ Main chat function â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export async function chat(messages: AIMessage[], dbContext?: string): Promise<string> {
  const config = getAIConfig();

  // Inject DB context into the last user message if available
  const enrichedMessages = [...messages];
  if (dbContext && enrichedMessages.length > 0) {
    const last = enrichedMessages[enrichedMessages.length - 1];
    if (last.role === 'user') {
      enrichedMessages[enrichedMessages.length - 1] = {
        ...last,
        content: `${last.content}\n\n[Datos actuales de la DB]\n${dbContext}`,
      };
    }
  }

  switch (config.provider) {
    case 'anthropic':
      if (!config.apiKey) return 'âš ï¸ API key de Anthropic no configurada. Ve a Config â†’ Asistente IA.';
      return callAnthropic(enrichedMessages, config);

    case 'openai':
    case 'custom':
      if (!config.apiKey) return 'âš ï¸ API key no configurada. Ve a Config â†’ Asistente IA.';
      return callOpenAI(enrichedMessages, config);

    case 'mock':
    default:
      const lastMsg = messages[messages.length - 1]?.content || '';
      return getMockResponse(lastMsg);
  }
}

// â”€â”€â”€ Available models per provider â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

export const PROVIDER_MODELS: Record<string, { label: string; models: { id: string; name: string }[] }> = {
  mock: { label: 'Mock (Sin API)', models: [{ id: 'mock', name: 'Respuestas locales' }] },
  anthropic: {
    label: 'Anthropic (Claude)',
    models: [
      { id: 'claude-sonnet-4-20250514', name: 'Claude Sonnet 4' },
      { id: 'claude-opus-4-20250514', name: 'Claude Opus 4' },
      { id: 'claude-3-5-haiku-20241022', name: 'Claude 3.5 Haiku (rÃ¡pido)' },
    ],
  },
  openai: {
    label: 'OpenAI',
    models: [
      { id: 'gpt-4o', name: 'GPT-4o' },
      { id: 'gpt-4o-mini', name: 'GPT-4o Mini (rÃ¡pido)' },
      { id: 'gpt-4-turbo', name: 'GPT-4 Turbo' },
    ],
  },
  custom: {
    label: 'Custom (OpenAI-compatible)',
    models: [
      { id: 'custom', name: 'Modelo personalizado' },
    ],
  },
};
